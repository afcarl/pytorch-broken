{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "C62CAACE975D4CB4B559FC73BF55F3D7"
   },
   "source": [
    "# ByteNet in Pytorch\n",
    "\n",
    "Thomas Viehmann\n",
    "\n",
    "## Important note: This does not seem to work yet.\n",
    "\n",
    "This is the ByteNet model presented in [Kalchbenner et al., Neural Machine Translation in Linear Time](https://arxiv.org/abs/1610.10099).\n",
    "\n",
    "In producing this I also looked at\n",
    "- [Namju Kim's implementation](https://github.com/buriburisuri/ByteNet) using his SugarTensor framework\n",
    "- [Paarth Neekhara implementation](https://github.com/paarthneekhara/byteNet-tensorflow) in plain tensorflow\n",
    "\n",
    "All bugs are my own.\n",
    "\n",
    "As dataset I used [the ComTrans sample from NLTK](https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/packages/corpora/comtrans.zip), see the [NLTK data](http://www.nltk.org/nltk_data/) page. The dataset loads the unzipped files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cell_id": "9F09A908283A400CAF0E315DD83033F7",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.utils.data\n",
    "\n",
    "import collections\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cell_id": "054631EAD8664E1A886CC0A0620A0B74",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# really simple validation splitter\n",
    "class PartialDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, parent_ds, offset=None, length=None, idx_list=None):\n",
    "        self.parent_ds = parent_ds\n",
    "        if idx_list is None:\n",
    "            assert (offset is not None and length is not None), \"Either idx_list or both offset and length need to be passed\"\n",
    "            assert len(parent_ds)>=offset+length, Exception(\"Parent Dataset not long enough\")\n",
    "            self.idx_list = torch.arange(0,len(parent_ds)).long()[offset:offset+length]\n",
    "        else:\n",
    "            assert (offset is None and length is None), \"Only either idx_list or both offset and length need to be passed\"\n",
    "            self.idx_list = idx_list\n",
    "        super(PartialDataset, self).__init__()\n",
    "    def __len__(self):\n",
    "        return self.idx_list.size(0)\n",
    "    def __getitem__(self, i):\n",
    "        return self.parent_ds[self.idx_list[i]]\n",
    "\n",
    "def validation_split(dataset, val_share=0.1, shuffle=True):\n",
    "    \"\"\"\n",
    "       Split a (training and vaidation combined) dataset into training and validation.\n",
    "       Note that to be statistically sound, the items in the dataset should be statistically\n",
    "       independent (e.g. not sorted by class, not several instances of the same dataset that\n",
    "       could end up in either set).\n",
    "    \n",
    "       inputs:\n",
    "          dataset:   (\"training\") dataset to split into training and validation\n",
    "          val_share: fraction of validation data (should be 0<val_share<1, default: 0.1)\n",
    "          shuffle:   pick random items for each part\n",
    "       returns: input dataset split into test_ds, val_ds\n",
    "       \n",
    "       \"\"\"\n",
    "    val_offset = int(len(dataset)*(1-val_share))\n",
    "    if shuffle:\n",
    "        idxes = torch.randperm(len(dataset))\n",
    "    else:\n",
    "        idxes = torch.arange(0, len(dataset)).long()\n",
    "    return PartialDataset(dataset, 0, val_offset), PartialDataset(dataset, idx_list=idxes)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "309DF63D8D5545EB81362CC0C6E1B4BC"
   },
   "source": [
    "A very basic Dataset class for the ComTrans dataset. See above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "cell_id": "6CD1347FCBD149B780909C6C0E281C0C",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ComTransChar(torch.utils.data.Dataset):\n",
    "    def __init__(self,fn=\"comtrans/alignment-de-en.txt\", min_len=50, max_len=150):\n",
    "        f = open(fn, encoding=\"latin_1\")\n",
    "        self.char_frequencies = collections.Counter()\n",
    "        self.corpus = []\n",
    "        self.max_len = max_len\n",
    "        while True:\n",
    "            src = f.readline().rstrip()\n",
    "            if not src:\n",
    "                break\n",
    "            tgt = f.readline().rstrip()\n",
    "            al  = [tuple(int(i) for i in p.split('-')) for p in f.readline().rstrip().split()]\n",
    "            if min_len<=len(src)<=max_len and min_len<=len(tgt)<=max_len:\n",
    "                self.corpus.append((src,tgt,al))\n",
    "                self.char_frequencies.update(src)\n",
    "                self.char_frequencies.update(tgt)\n",
    "        self.idx_to_char = dict(enumerate(['','<EOS>']+sorted(self.char_frequencies)))\n",
    "        self.char_to_idx = {v:k for k,v in self.idx_to_char.items()}\n",
    "        \n",
    "        self.src_tensor = torch.LongTensor(len(self.corpus), self.max_len + 1).zero_()\n",
    "        self.tgt_tensor = torch.LongTensor(len(self.corpus), self.max_len + 1).zero_()\n",
    "        \n",
    "        for i,(s,t,_) in enumerate(self.corpus):\n",
    "            self.src_tensor[i, :len(s)] = torch.LongTensor([self.char_to_idx[c] for c in s])\n",
    "            self.src_tensor[i, len(s)] = 1 # <EOS>\n",
    "            self.tgt_tensor[i, :len(t)] = torch.LongTensor([self.char_to_idx[c] for c in t])\n",
    "            self.tgt_tensor[i, len(t)] = 1 # <EOS>\n",
    "    def __len__(self):\n",
    "        return len(self.corpus)\n",
    "    def __getitem__(self, i):\n",
    "        return (self.src_tensor[i], self.tgt_tensor[i])\n",
    "    def tensor_to_str(self, t, cut_at_eos=True):\n",
    "        res = [self.idx_to_char[i] for i in t]\n",
    "        if cut_at_eos:\n",
    "            res = res[:(res+['<EOS>']).index('<EOS>')]\n",
    "        return ''.join(res)\n",
    "    def tensors_to_strs(self, *args, cut_at_eos=True):\n",
    "        return [self.tensor_to_str(t, cut_at_eos=cut_at_eos) for t in args]\n",
    "    def encode_strs(self, strs, max_len=None):\n",
    "        if max_len is None:\n",
    "            max_len = self.max_len\n",
    "        if type(strs) == str:\n",
    "            strs = [strs]\n",
    "        res = torch.LongTensor(len(strs), max_len).zero_()\n",
    "        for i,s in enumerate(strs):\n",
    "            res[i, :len(s)] = torch.LongTensor([self.char_to_idx[c] for c in s])\n",
    "            res[i, len(s)] = 1 # <EOS>\n",
    "        return res\n",
    "\n",
    "corpus = ComTransChar(max_len=95)\n",
    "#dl = torch.utils.data.DataLoader(corpus, batch_size=16, shuffle=True)\n",
    "\n",
    "train_ds, val_ds = validation_split(corpus, val_share=0.01)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_ds, batch_size=32, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(val_ds, batch_size=16, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "cell_id": "0F3E70971B26410389C8F1DE50214EFD",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ResUnit(nn.Module):\n",
    "    def __init__(self, in_channels, size=3, dilation=1, causal=False, in_ln=True):\n",
    "        super(ResUnit, self).__init__()\n",
    "        self.size = size\n",
    "        self.dilation = dilation\n",
    "        self.causal = causal\n",
    "        self.in_ln = in_ln\n",
    "        if self.in_ln:\n",
    "            self.ln1 = nn.InstanceNorm1d(in_channels, affine=True)\n",
    "            self.ln1.weight.data.fill_(1.0)\n",
    "        self.conv_in = nn.Conv1d(in_channels, in_channels//2, 1)\n",
    "        self.ln2 = nn.InstanceNorm1d(in_channels//2, affine=True)\n",
    "        self.ln2.weight.data.fill_(1.0)\n",
    "        self.conv_dilated = nn.Conv1d(in_channels//2, in_channels//2, size, dilation=self.dilation,\n",
    "                                      padding=((dilation*(size-1)) if causal else (dilation*(size-1)//2)))\n",
    "        self.ln3 = nn.InstanceNorm1d(in_channels//2, affine=True)\n",
    "        self.ln3.weight.data.fill_(1.0)\n",
    "        self.conv_out = nn.Conv1d(in_channels//2, in_channels, 1) \n",
    "\n",
    "    def forward(self, inp):\n",
    "        x = inp\n",
    "        if self.in_ln:\n",
    "            x = self.ln1(x)\n",
    "        x = nn.functional.relu(x)\n",
    "        x = nn.functional.relu(self.ln2(self.conv_in(x)))        \n",
    "        x = self.conv_dilated(x)\n",
    "        if self.causal and self.size>1:\n",
    "            x = x[:,:,:-self.dilation*(self.size-1)]\n",
    "        x = nn.functional.relu(self.ln3(x))\n",
    "        x = self.conv_out(x)\n",
    "        return x+inp\n",
    "\n",
    "class ResBlock(nn.Sequential):\n",
    "    def __init__(self, in_channels, size=5, causal=False):\n",
    "        super(ResBlock, self).__init__(\n",
    "                ResUnit(in_channels, size=size, dilation=1,  causal=causal, in_ln=False),\n",
    "                ResUnit(in_channels, size=size, dilation=2,  causal=causal),\n",
    "                ResUnit(in_channels, size=size, dilation=4,  causal=causal),\n",
    "                ResUnit(in_channels, size=size, dilation=8,  causal=causal),\n",
    "                ResUnit(in_channels, size=size, dilation=16, causal=causal)\n",
    "            )\n",
    "\n",
    "class Encoder(nn.Sequential):\n",
    "    def __init__(self, in_channels, num_blocks = 3):\n",
    "        super(Encoder, self).__init__(*([ResBlock(in_channels) for i in range(num_blocks)]+\n",
    "                                         [nn.ReLU(),\n",
    "                                          nn.Conv1d(in_channels, in_channels, 1),\n",
    "                                          nn.ReLU()]))\n",
    "        \n",
    "\n",
    "class Decoder(nn.Sequential):\n",
    "    def __init__(self, in_channels, num_chars, num_blocks = 3):\n",
    "        super(Decoder, self).__init__(*([ResBlock(in_channels, size=3, causal=True) for i in range(num_blocks)]+\n",
    "                                        [nn.Conv1d(in_channels, num_chars, 1)]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "cell_id": "B9919D7DD9764874882F0B151A97FAE0",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hidden_dim = 400 # half of in the Kalchbrenner et al., section 6\n",
    "num_chars = len(corpus.char_to_idx)\n",
    "src_embedder = nn.Embedding(num_embeddings=num_chars, embedding_dim=hidden_dim, padding_idx=0)\n",
    "tgt_embedder = nn.Embedding(num_embeddings=num_chars, embedding_dim=hidden_dim, padding_idx=0)\n",
    "\n",
    "encoder = Encoder(hidden_dim)\n",
    "decoder = Decoder(2*hidden_dim, len(corpus.char_to_idx))\n",
    "\n",
    "src_embedder.cuda()\n",
    "tgt_embedder.cuda()\n",
    "encoder.cuda()\n",
    "decoder.cuda()\n",
    "\n",
    "loss_class_weights = torch.ones(num_chars).cuda()\n",
    "loss_class_weights[0] = 0.0\n",
    "ce_loss = torch.nn.CrossEntropyLoss(weight=loss_class_weights)\n",
    "\n",
    "allparams = sum([list(m.parameters()) for m in [src_embedder, tgt_embedder, encoder, decoder]],[])\n",
    "optim = torch.optim.Adam(allparams, lr=1e-4, betas=(0.5,0.75))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "cell_id": "92B1374AB6C848288A25178AB13EB3A4",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 300 0 183 21:02:17 21:07:59 5.128349304199219\n",
      "Mit unseren Änderungsanträgen wollen wir die Beteiligung der Verbände stärken .\n",
      "Daraus müssen wir dann aber auch Schlußfolgerungen ziehen .\n",
      "Die Änderungsanträge 1 und 13 sind sprachliche Präzisierungen .\n",
      "Der dritte Aspekt betrifft das Subsidiaritätsprinzip , auf das sich die Union stützt .\n",
      "Ich möchte noch auf einen weiteren Aspekt eingehen .\n",
      " c.r   ja   t a B8aQ Pr\n",
      " o c  K l c uc aori  t e6ta o  l tieo Áo a . Br ¾o j .¾ r oBÁoy  mB ¾dK\n",
      " BGèi e oK e  r ra ie U ( .  e \"  r B ore  \n",
      " j ma oo\n",
      " BKa  rq  \n",
      "The aim of our amendments is to increase the participation of associations .\n",
      "But we should draw the necessary conclusions from this .\n",
      "Amendments Nos 1 and 3 concern linguistic nuances .\n",
      "The third aspect concerns the principle of subsidiarity that underpins the European Union .\n",
      "I will give you an additional piece of information .\n",
      "0 300 100 183 21:02:42 00:52:50 1.7800085544586182\n",
      "Wir müssen das gräßliche Übel des sexuellen Mißbrauchs von Kindern bekämpfen .\n",
      "Das liegt nicht im Interesse der einfachen Menschen in Europa .\n",
      "Einige Kollegen werden sich dazu wohl noch äußern .\n",
      "Da sich niemand zu Wort meldet , lasse ich über diesen Antrag abstimmen .\n",
      "Von daher gesehen sind wir der Zeit ein Stück hinterher gelaufen .\n",
      "our to seres are in the cour bet ares .\n",
      "our and are are and actere stath .\n",
      "one praction is the dement .\n",
      "our atall ame ane ale are of the on all tean .\n",
      "I there ale ale tial in the suprectis of of .\n",
      "We must tackle a dreadful scourge , the sexual exploitation of children .\n",
      "This is not in the interest of the ordinary people of Europe .\n",
      "I think that a number of MEPs will make reference to this .\n",
      "Since no one wishes to speak , I shall put this proposal to the vote .\n",
      "From this point of view we are slightly behind the times .\n",
      "1 300 0 183 21:03:03 00:17:45 1.4458389282226562\n",
      "( Das Parlament lehnt den Entschließungsantrag ab . )\n",
      "Darüber sollten wir mindestens so stark diskutieren wie über die Verschärfung des Strafrechts .\n",
      "Herr Markov , Sie werden in einigen Minuten fünf oder sechs Minuten zur Verfügung haben .\n",
      "Es gibt zu wenig junge Menschen , die das Risiko der Selbständigkeit auf sich nehmen wollen .\n",
      "8 - erhöht die Einbeziehung der Bürger in den Entscheidungsprozeß zum Standort der Anlagen ,\n",
      "reat sare ate anoter .\n",
      "I amentarinestingerestaning .\n",
      "I ampisiting anderstand too are and .\n",
      "I amonested to anerestingeasten arofitination .\n",
      "I ampestanaines foresting and and ande .\n",
      "( Parliament rejected the motion for a resolution )\n",
      "We should discuss this in at least as much detail as the tightening of criminal law .\n",
      "Mr Markov , in five or six minutes time , you will be allowed a few minutes to speak .\n",
      "There are too few young people who are willing to take the risk of being self-employed .\n",
      "8 . Increases the role of the public in decision making on the siting of installations .\n",
      "1 300 100 183 21:03:29 00:54:08 1.4332821369171143\n",
      "Aber das bedeutet nicht , von dieser Liste würden Zusätze gestrichen .\n",
      "Zweitens : Der Bericht widerspricht an einigen Stellen dem Vertrag .\n",
      "Das wäre fast wie die Warnhinweise , wie man sie auf Zigarettenpackungen findet .\n",
      "In diesem Sinne befürworte ich die Vorschläge von Herrn Sakellariou .\n",
      "Flexibilität ist auch im Hinblick auf die Länder mit geringen Finanzmitteln notwendig .\n",
      "enenditices anopevention is .\n",
      "neatest dimenes to thes tereste .\n",
      "our that .\n",
      "ures thened to seeplate .\n",
      "our peastic stamen the fumone .\n",
      "It does not , however , mean deleting any additives from the list .\n",
      "Secondly , the report also contradicts the Treaty at certain points .\n",
      "It would be more like the kind of warning you find on cigarette packets .\n",
      "In this sense , I am in agreement with Mr Sakellariou ' s proposals .\n",
      "There must be flexibility also for countries with small budgets .\n",
      "2 300 0 183 21:03:50 00:18:46 1.0690040588378906\n",
      "Erfreulicherweise stellen diese Änderungen im großen und ganzen Verbesserungen dar .\n",
      "Daran mitzuwirken , ist die Aufgabe eines jeden von uns .\n",
      "Wir dürfen nicht länger warten , denn dieses Volk ist vom Aussterben bedroht .\n",
      "Dazu brauchen wir eine klimaschonende Energie , die Atomenergie .\n",
      "( FR ) Dieser Bericht verweist uns auf die Frage , wozu die Regionalpolitik eigentlich da ist .\n",
      "I ampolicher spartices are .\n",
      "our pot menist we chores .\n",
      "oresines .\n",
      "our sarment one regords .\n",
      "onet ressinst counts .\n",
      "Happily , all these changes are , on the whole , improvements .\n",
      "It is up to each and every one of us to work on this .\n",
      "There is no time to lose ; this people could cease to exist .\n",
      "For that we need a form of energy production that does not harm the climate : nuclear energy .\n",
      "( FR ) This report takes us back to the question of why we even have a regional policy .\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-2a0c9171dd18>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mtgt_emb_prev\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtgt_embedder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtgt_prev\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0menc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc_emb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0menc_and_prev\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0menc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt_emb_prev\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-07e357b5021a>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inp)\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcausal\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdilation\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mln3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv_out\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/nn/modules/instancenorm.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;31m# Apply instance norm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0minput_reshaped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         out = F.batch_norm(\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_epochs = 300\n",
    "last_time = time.time()\n",
    "print_steps = 100\n",
    "for epoch in range(num_epochs):\n",
    "    for i,(src,tgt) in enumerate(train_loader):\n",
    "        optim.zero_grad()\n",
    "        tgt_prev = torch.cat([torch.LongTensor(tgt.size(0), 1).zero_(), tgt[:,:-1]], dim=1)\n",
    "        src = Variable(src.cuda())\n",
    "        tgt = Variable(tgt.cuda())\n",
    "        tgt_prev = Variable(tgt_prev.cuda())\n",
    "        \n",
    "        src_emb = src_embedder(src).transpose(1,2)\n",
    "        tgt_emb = tgt_embedder(tgt).transpose(1,2)\n",
    "        tgt_emb_prev = tgt_embedder(tgt_prev).transpose(1,2)\n",
    "        \n",
    "        enc = encoder(src_emb)\n",
    "        enc_and_prev = torch.cat([enc, tgt_emb_prev], dim=1)\n",
    "        \n",
    "        dec = decoder(enc_and_prev).transpose(1,2).contiguous()\n",
    "        \n",
    "        dec_lin = dec.view(-1, num_chars)\n",
    "\n",
    "        loss = ce_loss(dec_lin, tgt.view(-1)) # note this does not weight by length\n",
    "        \n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        \n",
    "        if i % print_steps == 0:\n",
    "            this_time = time.time()\n",
    "            perstep = (this_time-last_time)/print_steps\n",
    "            stepstogo = len(train_loader)*(num_epochs-epoch)-i\n",
    "            target_time = time.localtime(this_time+stepstogo*perstep)\n",
    "            last_time = this_time\n",
    "            print (epoch, num_epochs, i, len(train_loader), time.strftime(\"%H:%M:%S\",time.localtime()),\n",
    "                   time.strftime(\"%H:%M:%S\",target_time), loss.data[0])\n",
    "            test,sol = next(val_loader.__iter__()) #corpus.encode_strs('Sind wir schon gut ?')\n",
    "            test = Variable(test.cuda())\n",
    "            enc = src_embedder(test).transpose(1,2)\n",
    "            enc_and_prev = torch.cat([enc, Variable(torch.zeros(enc.size()).cuda())],dim=1)\n",
    "            res = torch.LongTensor(test.size(0),corpus.max_len).zero_()\n",
    "            for i in range(corpus.max_len-1):\n",
    "                output = decoder(enc_and_prev)[:,:,i]\n",
    "                _,idx = output.max(1)\n",
    "                #if idx.data.max()>100:\n",
    "                #    print (\"idx\",output.size(), idx.data.max())\n",
    "                res[:,i] = idx.data\n",
    "                #if res.max()>100:\n",
    "                #    print (output.size(), idx.data.max(), res.max())\n",
    "                res_emb = tgt_embedder(idx)\n",
    "                enc_and_prev.data[:,hidden_dim:,i+1] = res_emb.data\n",
    "            print ('\\n'.join( corpus.tensors_to_strs(*test.data[:5].cpu())\n",
    "                              +corpus.tensors_to_strs(*res[:5])+corpus.tensors_to_strs(*sol[:5])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "5E8345686BD44F7CB05F3F07AF25F876",
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
